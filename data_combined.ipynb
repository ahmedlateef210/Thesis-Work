{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e975938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f14b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_template = {\"Rainfall\":np.nan, \"Humidity\":np.nan, \"Tmax\":np.nan, \"Tmin\":np.nan, \"Tavg\":np.nan, \"Wind_spd\":np.nan, \"Wind_dir\":np.nan, \"Cloud_amt\":np.nan, \"Present_weather\":\"\", \"Past_weather\":\"\", \"Area_threshold\":np.nan, \"River\":'' ,\"max_wl\":np.nan, \"min_wl\":np.nan, \"avg_wl\":np.nan }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce0ffad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = pd.read_csv(\"BmdData/Rainfall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4ddbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"BmdData/Rainfall.csv\",\"r\") as rainfall_file:\n",
    "#     print(rainfall_file.read())    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dce7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [{\"station\": bogura, \"date\": year-month-day, \"rainfall\": nm, \"wa\": np.nan, \"d\" : d, },p\n",
    "# template_dict{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d55a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogura\n",
      "Chattogram\n",
      "Chuadanga\n",
      "Coxs Bazar\n",
      "Dhaka\n",
      "Dinajpur\n",
      "Mymensingh\n",
      "Netrokona\n",
      "Rajshahi\n",
      "Rangamati\n",
      "Rangpur\n",
      "Srimongal\n",
      "Sylhet\n",
      "Teknaf\n"
     ]
    }
   ],
   "source": [
    "combined_data = {}\n",
    "\n",
    "with open(\"BmdData/Rainfall.csv\",\"r\") as rainfall_file:\n",
    "    lines = rainfall_file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "\n",
    "##Finding Station Names    \n",
    "        if \"Station\" in line:\n",
    "            station = line[line.find(\":\")+1:line.find(\",\")-1].strip()   \n",
    "            print(station)\n",
    "        else:\n",
    "            year = line[:4]\n",
    "            try:\n",
    "                year = int(year)\n",
    "                data = line.split(\",\")\n",
    "\n",
    "                for day in range(1,32):\n",
    "                    date = f\"{year}/{data[1].strip()}/{day}\"\n",
    "                    if date in combined_data:\n",
    "                        combined_data[date][station] = copy.deepcopy(parameter_template) \n",
    "                    else:\n",
    "                        combined_data[date]= {station: copy.deepcopy(parameter_template)}\n",
    "                    combined_data[date][station][\"Rainfall\"] = int(data[day+1])\n",
    "                    \n",
    "                               \n",
    "            except ValueError:\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bdf5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 73, 'Humidity': nan, 'Tmax': nan, 'Tmin': nan, 'Tavg': nan, 'Wind_spd': nan, 'Wind_dir': nan, 'Cloud_amt': nan, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2000/9/1']['Dhaka'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae39a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"BmdData/RH.csv\",\"r\") as humidity_file:\n",
    "    lines = humidity_file.readlines()\n",
    "\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "##Finding Station Names    \n",
    "        if \"Station\" in line:\n",
    "            station = line[line.find(\":\")+1:line.find(\",\",line.find(\":\")+1)].strip()   \n",
    "#             print(station)  \n",
    "        else:\n",
    "            year = line[:4]\n",
    "            try:\n",
    "                year = int(year)\n",
    "                data = line.split(\",\")\n",
    "                \n",
    "                for day in range(1,32):\n",
    "                    \n",
    "                    date = f\"{year}/{data[1].strip()}/{day}\"\n",
    "                    \n",
    "                    \n",
    "                    if date in combined_data and station in combined_data[date]:\n",
    "#                         print(date, station)\n",
    "                        \n",
    "                        combined_data[date][station]['Humidity'] = int(data[day+1])\n",
    "                    \n",
    "                    elif date in combined_data:\n",
    "#                         print(line, station)\n",
    "                        combined_data[date][station] = copy.deepcopy(parameter_template) \n",
    "                    else:\n",
    "                        combined_data[date]= {station: copy.deepcopy(parameter_template)}\n",
    "                    combined_data[date][station][\"Humidity\"] = int(data[day+1])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                 \n",
    "            except ValueError:\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23597cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combined_data['1990/9/1']['Bogra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95acc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32a7bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n",
      "Teknaf\n"
     ]
    }
   ],
   "source": [
    "with open(\"BmdData/Tavg.csv\",\"r\") as t_avg:\n",
    "    lines = t_avg.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "#Finding Station Names    \n",
    "        if \"Temperature\" in line:\n",
    "#             station = line[line.find(\"of \")+2:line.find(\",\",line.find(\":\")+1)].strip()   \n",
    "            print(station)  \n",
    "        else:\n",
    "            year = line[6:10]\n",
    "#             print(year)\n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            data = line.split(\",\")\n",
    "    #                 print(data)\n",
    "\n",
    "            for day in range(1,32):\n",
    "\n",
    "                date = f\"{year}/{data[2].strip()}/{day}\"\n",
    "    #                     print(date)\n",
    "                \n",
    "                try:\n",
    "                    curr = data[day+2]\n",
    "                    if curr == \"\" or curr == \"****\":\n",
    "                        curr = np.nan\n",
    "                except IndexError:\n",
    "                    curr = np.nan\n",
    "               \n",
    "\n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "    #                         print(date, station, combined_data[date][station], len(data), data)\n",
    "\n",
    "                    try:\n",
    "                        combined_data[date][station]['Tavg'] = float(curr)\n",
    "                    except:\n",
    "                        print(date, station, data, line)\n",
    "                        print(curr)\n",
    "                        exit()\n",
    "\n",
    "\n",
    "                elif date in combined_data:\n",
    "\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                combined_data[date][station]['Tavg'] = float(curr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57d86c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 78, 'Tmax': nan, 'Tmin': nan, 'Tavg': nan, 'Wind_spd': nan, 'Wind_dir': nan, 'Cloud_amt': nan, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2022/2/1']['Dinajpur'])\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca6f4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"BmdData/Tmax.csv\",\"r\") as t_max:\n",
    "    lines = t_max.readlines()\n",
    "               \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "\n",
    "#Finding Station Names    \n",
    "        if \"Station\" in line:\n",
    "            station = line[line.find(\":\")+1:line.find(\",\")-1].strip()   \n",
    "#             print(station)  \n",
    "        else:\n",
    "            year = line[:4]\n",
    "            \n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "#             print(year)\n",
    "        \n",
    "            data = line.split(\",\")\n",
    "#             print(data)\n",
    "\n",
    "            for day in range(1,32):\n",
    "\n",
    "                date = f\"{year}/{data[1].strip()}/{day}\"\n",
    "#                 print(date)\n",
    "                \n",
    "                try:\n",
    "                    curr = data[day+2]\n",
    "                    if curr == \"\" or \"****\" in curr:\n",
    "                        curr = np.nan\n",
    "                except IndexError:\n",
    "                    curr = np.nan\n",
    "               \n",
    "\n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "    #                         print(date, station, combined_data[date][station], len(data), data)\n",
    "#                     print(date, curr)\n",
    "                    try:\n",
    "                        combined_data[date][station]['Tmax'] = float(curr)\n",
    "                    except:\n",
    "#                         print(date, station, data, line)\n",
    "#                         print(curr)\n",
    "                        exit()\n",
    "\n",
    "\n",
    "                elif date in combined_data:\n",
    "\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                \n",
    "                combined_data[date][station]['Tmax'] = float(curr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d921ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 78, 'Tmax': 20.5, 'Tmin': nan, 'Tavg': nan, 'Wind_spd': nan, 'Wind_dir': nan, 'Cloud_amt': nan, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2022/2/1']['Dinajpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a057ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogura\n",
      "Chattogram\n",
      "Chuadanga\n",
      "Coxs Bazar\n",
      "Dhaka\n",
      "Dinajpur\n",
      "Mymensingh\n",
      "Netrokona\n",
      "Rajshahi\n",
      "Rangpur\n",
      "Srimongal\n",
      "Sylhet\n",
      "Teknaf\n"
     ]
    }
   ],
   "source": [
    "with open(\"BmdData/Tmin.csv\",\"r\") as t_min:\n",
    "    lines = t_min.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "#Finding Station Names    \n",
    "        if \"Station\" in line:\n",
    "            station = line[line.find(\":\")+1:line.find(\",\")-1].strip()   \n",
    "            print(station)  \n",
    "        else:\n",
    "            year = line[:4]\n",
    "            \n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "#             print(year)\n",
    "        \n",
    "            data = line.split(\",\")\n",
    "#             print(data)\n",
    "\n",
    "            for day in range(1,32):\n",
    "\n",
    "                date = f\"{year}/{data[1].strip()}/{day}\"\n",
    "#                 print(date)\n",
    "                \n",
    "                try:\n",
    "                    curr = data[day+2]\n",
    "                    if curr == \"\" or \"****\" in curr:\n",
    "                        curr = np.nan\n",
    "                except IndexError:\n",
    "                    curr = np.nan\n",
    "               \n",
    "\n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "    #                         print(date, station, combined_data[date][station], len(data), data)\n",
    "#                     print(date, curr)\n",
    "                    try:\n",
    "                        combined_data[date][station]['Tmin'] = float(curr)\n",
    "                    except:\n",
    "                        print(date, station, data, line)\n",
    "                        print(curr)\n",
    "                        exit()\n",
    "\n",
    "\n",
    "                elif date in combined_data:\n",
    "\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                combined_data[date][station]['Tmin'] = float(curr)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdbe9c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 78, 'Tmax': 20.5, 'Tmin': 9.3, 'Tavg': nan, 'Wind_spd': nan, 'Wind_dir': nan, 'Cloud_amt': nan, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2022/2/1']['Dinajpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e1c124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogura\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Bogura       ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Chattogram\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Chattogram,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Chuadanga\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Chuadanga   ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Coxs Bazar\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Coxs Bazar ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Dhaka\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Dhaka       ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Dinajpur\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Dinajpur    ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Mymensingh\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Mymensingh  ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Netrokona\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Netrokona   ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Rajshahi\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Rajshahi    ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Rangamati\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Rangamati   ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Rangpur\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Rangpur     ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Srimongal\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Srimongal   ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Sylhet\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Sylhet      ,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Teknaf\n",
      "Daily Prevailing Wind Speed in Knots and Direction of Teknaf      ,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "with open(\"BmdData/Wind.csv\",\"r\") as wind:\n",
    "    lines = wind.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "\n",
    "#Finding Station Names    \n",
    "        if \"Knots\" in line:\n",
    "            station = line[line.find(\"of\")+2:line.find(\",\")].strip()   \n",
    "            print(station) \n",
    "            print(line)\n",
    "        else:\n",
    "            year = line[:4]\n",
    "            \n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "#             print(year)\n",
    "        \n",
    "            data = line.split(\",\")\n",
    "#             print(data)\n",
    "            \n",
    "            cur_speed = 2\n",
    "            cur_direc = 3\n",
    "            \n",
    "            for month in range(1,13):\n",
    "                \n",
    "\n",
    "                date = f\"{year}/{month}/{data[1].strip()}\"\n",
    "#                     print(date)\n",
    "\n",
    "                try:\n",
    "                    speed = data[cur_speed].strip()\n",
    "                    if speed == \"\" or \"****\" in speed:\n",
    "                        speed = np.nan\n",
    "                except IndexError:\n",
    "                    speed = np.nan\n",
    "\n",
    "                try:\n",
    "                    direction = data[cur_direc].strip()\n",
    "                    if direction == \"\" or \"****\" in direction:\n",
    "                        direction = np.nan\n",
    "                except IndexError:\n",
    "                    direction = np.nan\n",
    "                \n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "                    try:\n",
    "                        combined_data[date][station]['Wind_spd'] = float(speed)\n",
    "                        combined_data[date][station]['Wind_dir'] = direction\n",
    "                    except:\n",
    "#                         print(date, station, data, line)\n",
    "#                         print(curr)\n",
    "                        exit()\n",
    "\n",
    "\n",
    "                elif date in combined_data:\n",
    "\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                \n",
    "                combined_data[date][station]['Wind_spd'] = float(speed)\n",
    "                combined_data[date][station]['Wind_dir'] = direction\n",
    "                \n",
    "\n",
    "\n",
    "                cur_speed = cur_speed + 2\n",
    "                cur_direc = cur_direc + 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52162d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 77, 'Tmax': 21.4, 'Tmin': 14.4, 'Tavg': nan, 'Wind_spd': 3.2, 'Wind_dir': 'NE', 'Cloud_amt': nan, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2000/2/1']['Rangpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7baf6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rajshahi\n",
      "Daily  average  cloud amount(octa)  data         of        Rajshahi    ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Rangamati\n",
      "Daily  average  cloud amount(octa)  data         of        Rangamati   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Rangpur\n",
      "Daily  average  cloud amount(octa)  data         of        Rangpur     ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Srimongal\n",
      "Daily  average  cloud amount(octa)  data         of        Srimongal   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Sylhet\n",
      "Daily  average  cloud amount(octa)  data         of        Sylhet      ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Teknaf\n",
      "Daily  average  cloud amount(octa)  data         of        Teknaf      ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# combined_data = {}\n",
    "with open(\"BmdData/Cloud-2.csv\",\"r\") as cloud_amt:\n",
    "    lines = cloud_amt.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "\n",
    "# #Finding Station Names    \n",
    "        if \"cloud\" in line:\n",
    "            station = line[line.find(\"of \")+2:line.find(\",\")-1].strip()   \n",
    "            print(station)  \n",
    "            print(line)\n",
    "        else:\n",
    "            year = line[6:10]\n",
    "            \n",
    "# #Finding year\n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "#             print(year)\n",
    "# #putting the line in a list\n",
    "            data = line.split(\",\")\n",
    "# #             print(data)\n",
    "\n",
    "            for day in range(1,32):\n",
    "\n",
    "                date = f\"{year}/{data[2].strip()}/{day}\"\n",
    "#                 print(date)\n",
    "                \n",
    "                try:\n",
    "                    curr = data[day+2]\n",
    "                    if curr == \"\" or \"***\" in curr:\n",
    "                        curr = np.nan\n",
    "                except IndexError:\n",
    "                    curr = np.nan\n",
    "               \n",
    "\n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "#                     print(date, station, combined_data[date][station])\n",
    "                    combined_data[date][station]['Cloud_amt'] = float(curr)\n",
    "                elif date in combined_data:\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                combined_data[date][station]['Cloud_amt'] = float(curr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ead28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 66, 'Tmax': 21.0, 'Tmin': 13.6, 'Tavg': nan, 'Wind_spd': 3.0, 'Wind_dir': 'E', 'Cloud_amt': 2.5, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2000/3/1']['Rangpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "393673d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogura\n",
      "Daily  average  cloud amount(octa)  data         of        Bogura       ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Chattogram\n",
      "Daily  average  cloud amount(octa)  data         of        Chattogram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Chuadanga\n",
      "Daily  average  cloud amount(octa)  data         of        Chuadanga   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Coxs Bazar\n",
      "Daily  average  cloud amount(octa)  data         of        Coxs Bazar ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Dhaka\n",
      "Daily  average  cloud amount(octa)  data         of        Dhaka       ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Dinajpur\n",
      "Daily  average  cloud amount(octa)  data         of        Dinajpur    ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Mymensingh\n",
      "Daily  average  cloud amount(octa)  data         of        Mymensingh  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Netrokona\n",
      "Daily  average  cloud amount(octa)  data         of        Netrokona   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "with open(\"BmdData/Cloud-1.csv\",\"r\") as cloud_amt:\n",
    "    lines = cloud_amt.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "#         print(line)\n",
    "\n",
    "\n",
    "#Finding Station Names    \n",
    "        if \"cloud\" in line:\n",
    "            station = line[line.find(\"of \")+2:line.find(\",\")].strip()   \n",
    "            print(station)\n",
    "            print(line)\n",
    "        else:\n",
    "            year = line[6:10]\n",
    "#             print(year)\n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            data = line.split(\",\")\n",
    "#             print(data)\n",
    "\n",
    "            for day in range(1,32):\n",
    "\n",
    "                date = f\"{year}/{data[2].strip()}/{day}\"\n",
    "#                 print(date)\n",
    "                \n",
    "                try:\n",
    "                    curr = data[day+2]\n",
    "                    if curr == \"\" or \"***\" in curr:\n",
    "                        curr = np.nan\n",
    "                except IndexError:\n",
    "                    curr = np.nan\n",
    "               \n",
    "\n",
    "                if date in combined_data and station in combined_data[date]:\n",
    "#                     print(date, station, combined_data[date][station])\n",
    "\n",
    "                    try:\n",
    "                        combined_data[date][station]['Cloud_amt'] = float(curr)\n",
    "                    except:\n",
    "#                         print(date, station, data, line)\n",
    "#                         print(curr)\n",
    "                        exit()\n",
    "\n",
    "\n",
    "                elif date in combined_data:\n",
    "\n",
    "                    combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "                else:\n",
    "                    combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "                \n",
    "                combined_data[date][station]['Cloud_amt'] = float(curr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4346507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 77, 'Tmax': 21.4, 'Tmin': 14.4, 'Tavg': nan, 'Wind_spd': 3.2, 'Wind_dir': 'NE', 'Cloud_amt': 2.0, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': nan, 'min_wl': nan, 'avg_wl': nan}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2000/2/1']['Rangpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2503d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# water_level_cox = pd.read_excel(\"water_level_data/Water_Level_CoxBazar.xlsx\")\n",
    "# water_level_cox.to_csv('water_level_data/Water_Level_CoxBazar.csv')\n",
    "\n",
    "# with open(\"water_level_data/Water_Level_CoxBazar.csv\",\"r\") as water_level_cox:\n",
    "#     lines = water_level_cox.readlines()\n",
    "    \n",
    "#     for line in range():\n",
    "        \n",
    "#         line = line.strip()\n",
    "#         data = line.split(\",\")\n",
    "#         print(data)\n",
    "\n",
    "#         print(line)\n",
    "        \n",
    "    \n",
    "#     station = data[2]\n",
    "#     river = data[4]\n",
    "    \n",
    "#     date = data[7]\n",
    "#     max_wl = data[8]\n",
    "#     min_wl = data[9]\n",
    "#     avg_wl = data[10]\n",
    "#     print(data, max_wl, min_wl, avg_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f340ccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogkhali Coxs Bazar\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"water_level_data/Water_Level_CoxBazar.xlsx\")\n",
    "\n",
    "river = df['RIVER'][0]\n",
    "station = df['DISTRICT'][0]\n",
    "sl = df['SL']\n",
    "\n",
    "print(river, station)\n",
    "\n",
    "for idx, mwl in enumerate(sl):\n",
    "    \n",
    "    date = df['DATE/TIME'][idx]\n",
    "    date = str(date)\n",
    "    \n",
    "    year = date[0:4].strip()\n",
    "    month = date[5:7].strip()\n",
    "    if month[0]=='0':\n",
    "        month = month[1]\n",
    "    day = date[8:10].strip()\n",
    "    if day[0]=='0':\n",
    "        day = day[1]\n",
    "    date = f\"{year}/{month}/{day}\"\n",
    "#     print(date)\n",
    "    \n",
    "#     'MAX_WL(m)', 'MIN_WL(m)', 'AVE_WL(m)'\n",
    "   \n",
    "    max_wl = df[\"MAX_WL(m)\"][idx]\n",
    "    min_wl = df[\"MIN_WL(m)\"][idx]\n",
    "    avg_wl = df[\"AVE_WL(m)\"][idx]\n",
    "    \n",
    "    if date in combined_data and station in combined_data[date]:\n",
    "    #                     print(date, station, combined_data[date][station])\n",
    "\n",
    "        try:\n",
    "            combined_data[date][station]['max_wl'] = float(max_wl)\n",
    "            combined_data[date][station]['min_wl'] = float(min_wl)\n",
    "            combined_data[date][station]['avg_wl'] = float(avg_wl)\n",
    "\n",
    "        except:\n",
    "#                         print(date, station, data, line)\n",
    "#                         print(curr)\n",
    "            exit()\n",
    "\n",
    "\n",
    "    elif date in combined_data:\n",
    "\n",
    "        combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "    else:\n",
    "        combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "\n",
    "    combined_data[date][station]['max_wl'] = float(max_wl)\n",
    "    combined_data[date][station]['min_wl'] = float(min_wl)\n",
    "    combined_data[date][station]['avg_wl'] = float(avg_wl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d87c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 65, 'Tmax': 33.5, 'Tmin': 21.5, 'Tavg': nan, 'Wind_spd': 6.0, 'Wind_dir': 'NNW', 'Cloud_amt': 0.0, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': 2.66, 'min_wl': 2.66, 'avg_wl': 2.66}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2003/3/1']['Coxs Bazar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "988582e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd372fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('water_level_data')\n",
    "\n",
    "for each in files:\n",
    "    fn = f'water_level_data/{each}'\n",
    "#     print(fn)\n",
    "    df = pd.read_excel(fn)\n",
    "\n",
    "    river = df['RIVER'][0]\n",
    "    station = df['DISTRICT'][0]\n",
    "    sl = df['SL']\n",
    "\n",
    "#     print(river, station)\n",
    "\n",
    "    for idx, mwl in enumerate(sl):\n",
    "\n",
    "        date = df['DATE/TIME'][idx]\n",
    "        date = str(date)\n",
    "\n",
    "        year = date[0:4].strip()\n",
    "        month = date[5:7].strip()\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        day = date[8:10].strip()\n",
    "        if day[0]=='0':\n",
    "            day = day[1]\n",
    "        date = f\"{year}/{month}/{day}\"\n",
    "    #     print(date)\n",
    "\n",
    "    #     'MAX_WL(m)', 'MIN_WL(m)', 'AVE_WL(m)'\n",
    "\n",
    "        max_wl = df[\"MAX_WL(m)\"][idx]\n",
    "        min_wl = df[\"MIN_WL(m)\"][idx]\n",
    "        avg_wl = df[\"AVE_WL(m)\"][idx]\n",
    "\n",
    "        if date in combined_data and station in combined_data[date]:\n",
    "        #                     print(date, station, combined_data[date][station])\n",
    "\n",
    "            try:\n",
    "                combined_data[date][station]['max_wl'] = float(max_wl)\n",
    "                combined_data[date][station]['min_wl'] = float(min_wl)\n",
    "                combined_data[date][station]['avg_wl'] = float(avg_wl)\n",
    "\n",
    "            except:\n",
    "    #                         print(date, station, data, line)\n",
    "    #                         print(curr)\n",
    "                exit()\n",
    "\n",
    "\n",
    "        elif date in combined_data:\n",
    "\n",
    "            combined_data[date][station] = copy.deepcopy(parameter_template)\n",
    "        else:\n",
    "            combined_data[date]= {station:  copy.deepcopy(parameter_template)}\n",
    "\n",
    "        combined_data[date][station]['max_wl'] = float(max_wl)\n",
    "        combined_data[date][station]['min_wl'] = float(min_wl)\n",
    "        combined_data[date][station]['avg_wl'] = float(avg_wl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498409bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rainfall': 0, 'Humidity': 66, 'Tmax': 33.4, 'Tmin': 22.6, 'Tavg': nan, 'Wind_spd': 2.0, 'Wind_dir': 'E', 'Cloud_amt': 0.0, 'Present_weather': '', 'Past_weather': '', 'Area_threshold': nan, 'River': '', 'max_wl': 26.51, 'min_wl': 26.51, 'avg_wl': 26.51}\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['2003/4/10']['Dinajpur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4115baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"BmdData/Past & Present weather_1990-2000 - Copy\",\"r\") as weather:\n",
    "\n",
    "# # # read text file into pandas DataFrame\n",
    "# #     df = pd.read_csv(\"Past & Present weather_1990-2000 - Copy\", sep=\" \") \n",
    "# #     print(df)\n",
    "#     lines = weather.readlines()\n",
    "\n",
    "#     for line in lines:\n",
    "#         line = line.strip()\n",
    "# #         print(line)\n",
    "\n",
    "#         data = line.split()\n",
    "#         try:\n",
    "#             year = int(data[1])\n",
    "#             print(year)\n",
    "#             print(data)\n",
    "#         except:\n",
    "#             print(data)\n",
    "# #             continue\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0cc9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_remove = []\n",
    "# to_add = []\n",
    "# for date, temp in combined_data.items():\n",
    "# #     for station, features in temp.items():\n",
    "        \n",
    "#         if station in [\"Cox's Bazar\",\"Cox'sbazar\",'Coxs Bazar']:\n",
    "#             new_station = 'Coxs Bazar'\n",
    "#         elif station in ['Ambaga','Ambagan','Ambagan(Ctg)', 'Chattogram']:\n",
    "#             new_station = 'Chattogram'\n",
    "#         elif station in ['Bagura','Bogra','Bogura']:\n",
    "#             new_station = 'Bogura'\n",
    "#         elif station in ['Chuadanga','Chudanga', 'chuadanga']:\n",
    "#             new_station = 'Chuadanga'\n",
    "#         elif station in ['Natrakona','Netrokona','Nettrokona']:\n",
    "#             new_station = 'Netrokona'\n",
    "#         elif station in ['Srimangal','Srimongal',]:\n",
    "#             new_station = 'Srimongal'\n",
    "#         elif station in ['rangpur','Rangpur']:\n",
    "#             new_station = 'Rangpur' \n",
    "        \n",
    "#         if new_station in combined_data[date]:\n",
    "#             for key in features.keys():\n",
    "#                 if features[key] not in [np.nan, \"\"]:\n",
    "#                     combined_data[date][new_station][key] = combined_data[date][station][key]\n",
    "#         else:\n",
    "#             to_add.append((date, new_station, features)) \n",
    "#         to_remove.append((date, station))\n",
    "\n",
    "# for date, new_station, features in to_add:\n",
    "#     combined_data[date][new_station] = features\n",
    "# for date, station in to_remove:\n",
    "#     del combined_data[date][station]\n",
    "# # final_dataset = pd.DataFrame(combined_data)\n",
    "# # print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42314e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for date, temp in combined_data.items():\n",
    "    for station, features in temp.items():\n",
    "        x = copy.deepcopy(features)\n",
    "        \n",
    "#         if station in [\"Cox's Bazar\",\"Cox'sbazar\",'Coxs Bazar']:\n",
    "#             station = 'Coxs Bazar'\n",
    "#         elif station in ['Ambaga','Ambagan','Ambagan(Ctg)', 'Chattogram']:\n",
    "#             station = 'Chattogram'\n",
    "#         elif station in ['Bagura','Bogra','Bogura']:\n",
    "#             station = 'Bogura'\n",
    "#         elif station in ['Chuadanga','Chudanga', 'chuadanga']:\n",
    "#             station = 'Chuadanga'\n",
    "#         elif station in ['Natrakona','Netrokona','Nettrokona']:\n",
    "#             station = 'Netrokona'\n",
    "#         elif station in ['Srimangal','Srimongal',]:\n",
    "#             station = 'Srimongal'\n",
    "#         elif station in ['rangpur','Rangpur']:\n",
    "#             station = 'Rangpur' \n",
    "        \n",
    "        x['station'] = station\n",
    "        x['date'] = date\n",
    "        dataset_list.append(x)\n",
    "\n",
    "# final_dataset = pd.DataFrame(combined_data)\n",
    "# print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ee184ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rainfall  Humidity  Tmax  Tmin  Tavg  Wind_spd Wind_dir  Cloud_amt  \\\n",
      "0            0.0      84.0  21.0   8.5   NaN       4.5        W        0.0   \n",
      "1            0.0      80.0  21.6   6.0   NaN       2.0        N        NaN   \n",
      "2            0.0      66.0  25.5  14.3   NaN       7.0      NNE        0.0   \n",
      "3            0.0      68.0  23.4  11.4   NaN       4.4        N        0.0   \n",
      "4            0.0      82.0  18.0   8.4   NaN       1.7        W        0.0   \n",
      "...          ...       ...   ...   ...   ...       ...      ...        ...   \n",
      "219597       NaN       NaN  30.0   9.2   NaN       NaN      NaN        NaN   \n",
      "219598       NaN       NaN  32.5   NaN   NaN       NaN      NaN        NaN   \n",
      "219599       NaN       NaN  28.8  10.0   NaN       NaN      NaN        NaN   \n",
      "219600       NaN       NaN  31.5   7.7   NaN       NaN      NaN        NaN   \n",
      "219601       NaN       NaN  31.0  10.2   NaN       NaN      NaN        NaN   \n",
      "\n",
      "       Present_weather Past_weather  Area_threshold River  max_wl  min_wl  \\\n",
      "0                                               NaN           NaN     NaN   \n",
      "1                                               NaN          5.04    5.04   \n",
      "2                                               NaN          2.48    2.48   \n",
      "3                                               NaN           NaN     NaN   \n",
      "4                                               NaN           NaN     NaN   \n",
      "...                ...          ...             ...   ...     ...     ...   \n",
      "219597                                          NaN           NaN     NaN   \n",
      "219598                                          NaN           NaN     NaN   \n",
      "219599                                          NaN           NaN     NaN   \n",
      "219600                                          NaN           NaN     NaN   \n",
      "219601                                          NaN           NaN     NaN   \n",
      "\n",
      "        avg_wl     station       date  \n",
      "0          NaN      Bogura   1990/1/1  \n",
      "1         5.04   Chuadanga   1990/1/1  \n",
      "2         2.48  Coxs Bazar   1990/1/1  \n",
      "3          NaN       Dhaka   1990/1/1  \n",
      "4          NaN    Dinajpur   1990/1/1  \n",
      "...        ...         ...        ...  \n",
      "219597     NaN    Rajshahi  2022/2/31  \n",
      "219598     NaN   Rangamati  2022/2/31  \n",
      "219599     NaN     Rangpur  2022/2/31  \n",
      "219600     NaN   Srimongal  2022/2/31  \n",
      "219601     NaN      Sylhet  2022/2/31  \n",
      "\n",
      "[219602 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "final_dataset = pd.DataFrame(dataset_list)\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57bb2b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bogura', 'Chuadanga', 'Coxs Bazar', 'Dhaka', 'Dinajpur',\n",
       "       'Mymensingh', 'Rajshahi', 'Rangamati', 'Rangpur', 'Srimongal',\n",
       "       'Sylhet', 'Teknaf', 'Bandarban', 'Chattogram', 'Habiganj',\n",
       "       'Jamalpur', 'Sirajganj', 'Nilphamari', 'Netrokona'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset['station'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570d7267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bandarban',\n",
       " 'Bogura',\n",
       " 'Chattogram',\n",
       " 'Chuadanga',\n",
       " 'Coxs Bazar',\n",
       " 'Dhaka',\n",
       " 'Dinajpur',\n",
       " 'Habiganj',\n",
       " 'Jamalpur',\n",
       " 'Mymensingh',\n",
       " 'Netrokona',\n",
       " 'Nilphamari',\n",
       " 'Rajshahi',\n",
       " 'Rangamati',\n",
       " 'Rangpur',\n",
       " 'Sirajganj',\n",
       " 'Srimongal',\n",
       " 'Sylhet',\n",
       " 'Teknaf']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(final_dataset['station'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "738db3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rainfall  Humidity  Tmax  Tmin  Tavg  Wind_spd Wind_dir  Cloud_amt  \\\n",
      "0            0.0      84.0  21.0   8.5   NaN       4.5        W        0.0   \n",
      "1            0.0      80.0  21.6   6.0   NaN       2.0        N        NaN   \n",
      "2            0.0      66.0  25.5  14.3   NaN       7.0      NNE        0.0   \n",
      "3            0.0      68.0  23.4  11.4   NaN       4.4        N        0.0   \n",
      "4            0.0      82.0  18.0   8.4   NaN       1.7        W        0.0   \n",
      "...          ...       ...   ...   ...   ...       ...      ...        ...   \n",
      "219597       NaN       NaN  30.0   9.2   NaN       NaN      NaN        NaN   \n",
      "219598       NaN       NaN  32.5   NaN   NaN       NaN      NaN        NaN   \n",
      "219599       NaN       NaN  28.8  10.0   NaN       NaN      NaN        NaN   \n",
      "219600       NaN       NaN  31.5   7.7   NaN       NaN      NaN        NaN   \n",
      "219601       NaN       NaN  31.0  10.2   NaN       NaN      NaN        NaN   \n",
      "\n",
      "       Present_weather Past_weather  Area_threshold River  max_wl  min_wl  \\\n",
      "0                                               NaN           NaN     NaN   \n",
      "1                                               NaN          5.04    5.04   \n",
      "2                                               NaN          2.48    2.48   \n",
      "3                                               NaN           NaN     NaN   \n",
      "4                                               NaN           NaN     NaN   \n",
      "...                ...          ...             ...   ...     ...     ...   \n",
      "219597                                          NaN           NaN     NaN   \n",
      "219598                                          NaN           NaN     NaN   \n",
      "219599                                          NaN           NaN     NaN   \n",
      "219600                                          NaN           NaN     NaN   \n",
      "219601                                          NaN           NaN     NaN   \n",
      "\n",
      "        avg_wl     station       date  \n",
      "0          NaN      Bogura   1990/1/1  \n",
      "1         5.04   Chuadanga   1990/1/1  \n",
      "2         2.48  Coxs Bazar   1990/1/1  \n",
      "3          NaN       Dhaka   1990/1/1  \n",
      "4          NaN    Dinajpur   1990/1/1  \n",
      "...        ...         ...        ...  \n",
      "219597     NaN    Rajshahi  2022/2/31  \n",
      "219598     NaN   Rangamati  2022/2/31  \n",
      "219599     NaN     Rangpur  2022/2/31  \n",
      "219600     NaN   Srimongal  2022/2/31  \n",
      "219601     NaN      Sylhet  2022/2/31  \n",
      "\n",
      "[219602 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d9622ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv('dataset_v1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
